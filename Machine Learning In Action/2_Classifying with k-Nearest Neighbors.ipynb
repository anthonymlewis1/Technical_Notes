{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying with k-Nearest Neighbors\n",
    "\n",
    "## Classifying with distance measurements\n",
    "* Process:\n",
    "    * Start with a labeled training set\n",
    "    * Compare the unlabeled input to every piece of existing data\n",
    "    * Take the most similiar pieces of data (nearest neighbors)\n",
    "    * Look at the top k most similar pieces of labeled data\n",
    "    * Take a majority vote from the most similar pieces of data\n",
    "    * Unlabeled input gets labeled according to the majority vote\n",
    "\n",
    "* Pros:\n",
    "    * High accuracy\n",
    "    * Insensitive to outliers\n",
    "    * No assumptions about data\n",
    "* Cons:\n",
    "    * Computationally expensive\n",
    "    * Memory-intensive\n",
    "* Works with:\n",
    "    * Numeric values\n",
    "    * Nominal values\n",
    "\n",
    "* General Approach:\n",
    "    * Collect: Any method\n",
    "    * Prepare: Structured data format via numeric values are needed for a distance calculation\n",
    "    * Analyze: Any method\n",
    "    * Train: Does not apply to kNN algorithm\n",
    "    * Test: Calculate the error rate\n",
    "    * Use: Run through the processf\n",
    "\n",
    "* KNN in Pseudocode:\n",
    "* For every point in the dataset:\n",
    "    * Sort variable: inX\n",
    "    * Calculate the distance (Euclidean distance) between inX and the current point\n",
    "    * Sort the distances in increasing order\n",
    "    * Take the k items with the lowest distance to inX\n",
    "    * Find the majority class among these items\n",
    "    * Return the majority class as the prediction for inX\n",
    "\n",
    "## Testing a Classifier:\n",
    "    * Different things impact the performance of a classifier\n",
    "        * Settings of the classifier\n",
    "        * Dataset attributes\n",
    "    * Error Rate: Gauge for how good a classifier is on a dataset\n",
    "\n",
    "## Summary:\n",
    "* k-Nearest Neighbors is a simple and effective way to classify data\n",
    "* You need instances of data close at hand to perform the machine learning\n",
    "* Since you need the full dataset, this requires a large amount of storage\n",
    "* This also is a very computation-rich algorithm\n",
    "* Also does not show you what 'average' or 'exemplar' data is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
