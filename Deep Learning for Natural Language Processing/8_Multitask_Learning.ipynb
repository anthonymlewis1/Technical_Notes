{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: Multitask Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1: Introduction\n",
    "* Multitask learning = Learning several things are the same time\n",
    "    * Learn part-of-speech tagging and sentiment analysis together\n",
    "* We would primarily do multitask learning for classifier performance improvements\n",
    "    * Every ML algorithm suffers from inductive bias\n",
    "        * Inductive Bias = Implicit assumptions underlying computations\n",
    "            * Ex: Maximization of distances b/w classes in SVM.\n",
    "    * In Multitask learning, since they will both have the inductive bias, they can both try to optimize for one inductive bias\n",
    "        * Leads to better generalization properties of each task\n",
    "        * Makes for a more robust classifier\n",
    "\n",
    "## 8.2: Data\n",
    "* Restaurant / Electronic product reviews\n",
    "    * Will be used to test domain transfer\n",
    "    * Domain Transfer: Transferring knowledge from one domain to another during learning in order to supplement small data sets with more data\n",
    "* Reuters news dataset\n",
    "    * Given combinations of pairs of topics (A+B, C+D), can we create combinations that benefit the modeling of each topic?\n",
    "* Joint learning of Spanish pos tagging and named entity tagging\n",
    "    * Shared data with different labelings\n",
    "    * Can we get each learner to benefit from this?\n",
    "\n",
    "## 8.3: Consumer Reviews: Yelp and Amazon\n",
    "### 8.3.1: Data Handling\n",
    "* Loading the data flow:\n",
    "    * Data\n",
    "        * Documents(X)\n",
    "            * Vectorized documents\n",
    "            * Padded feature vectors\n",
    "        * Labels\n",
    "            * Labels converted to ints\n",
    "            * Vectorized labels\n",
    "\n",
    "* Single Task Sentiment Classifier Performance\n",
    "    * Amazon: 77.9%\n",
    "    * Yelp: 71.5%\n",
    "\n",
    "### 8.3.2: Hard Parameter Sharing\n",
    "```\n",
    "Task A Output           Task B Output\n",
    "        Task A + B Hidden Layer\n",
    "Task A Input            Task B Input\n",
    "```\n",
    "* We need to have our task-specific subnets share information!\n",
    "* Create a shared layer that combines some of the hidden layer info\n",
    "* Figuring out which layer to combine is discovered through experimentation\n",
    "    * Hyperparameter Optimization\n",
    "* To do this correctly, use the same classifier code from 8.3.1\n",
    "* Performance:\n",
    "    * Amazon: 54.5%\n",
    "    * Yelp: 76.5%\n",
    "    * So only Yelp did better\n",
    "\n",
    "### 8.3.3 Soft Parameter Sharing\n",
    "* Soft Parameter = Independent subnetworks that don't share layers but they are all constrained the same\n",
    "```\n",
    "Task A Output                 Task B Output\n",
    "            Task A + B Hidden Layer\n",
    "Task A Hidden Layer  <->   Task B Hidden Layer\n",
    "     |        (Loss Function)      |\n",
    "Task A Input                  Task B Input\n",
    "\n",
    "def custom_loss(a,b):\n",
    "        def loss(y_true,y_pred):\n",
    "            e1=keras.losses.categorical_crossentropy(y_true,y_pred)\n",
    "            e2=keras.losses.mean_squared_error(a,b)\n",
    "            e3=keras.losses.cosine_proximity(a,b)\n",
    "            e4=K.mean(K.square(a-b), axis=-1)\n",
    "            return e1+e2+e3+e4\n",
    "        return loss\n",
    "```\n",
    "* We can constrain them in the same way by having them share a custom loss function!\n",
    "    * Since a model measures its performance error with this\n",
    "    * Also allows for loss conditioning on arbitrary information\n",
    "    * The composition is kinda arbitrary a bit and open to experimentation\n",
    "        * Just depends on the pair of layers to work on, and teh composition of losses in the loss function\n",
    "\n",
    "* Performance:\n",
    "    * Amazon: 77.5%\n",
    "    * Yelp: 75%\n",
    "    * Better than our baseline!\n",
    "\n",
    "### 8.3.4 Mixed Parameter Sharing\n",
    "* Combination of hard and soft parameter sharing\n",
    "* The subnetworks share 1+ layers and adapt the internal parameters to each other\n",
    "```\n",
    "Task A Output                 Task B Output\n",
    "            Task A + B Hidden Layer\n",
    "Task A Hidden Layer  <->   Task B Hidden Layer\n",
    "     |                              |\n",
    "Task A Input                  Task B Input\n",
    "```\n",
    "* Performance: \n",
    "    * Amazon: 74%\n",
    "    * Yelp: 69.5%\n",
    "    * Worse than the single classifier!\n",
    "\n",
    "## 8.4 Reuters Topic Classification\n",
    "* Reuters dataset is a part of Keras' library\n",
    "* Texts are encoded as integer-based vectors w/ each integer representing a unique word\n",
    "\n",
    "### 8.4.1 Data Handling\n",
    "* For 2 pairs of topics, which pair can be learned as a separate additional task such that both tasks benefit?\n",
    "* one-versus-one classification:\n",
    "    * For N classes, train n(n-1)/2 binary classifiers\n",
    "    * Compute per test document the most assigned class label\n",
    "    * Then assign that label to the document\n",
    "* Loading the data flow:\n",
    "    * Data\n",
    "        * Topic Combinations\n",
    "            * Documents(X)\n",
    "                * Vectorized documents\n",
    "                * Padded feature vectors\n",
    "            * Labels\n",
    "                * Labels converted to ints\n",
    "                * Vectorized labels\n",
    "\n",
    "### 8.4.2 Hard Parameter Sharing\n",
    "* For each pair of topics, find another pair of two topics, and learn those two two-class problems together!\n",
    "* Performance:\n",
    "    * Pretty good job even for the low-scoring topics!\n",
    "\n",
    "### 8.4.3 Soft Parameter Sharing\n",
    "* Rinse and repeat for 8.3.3 which is that it did the best\n",
    "\n",
    "### 8.4.4 Mixed Parameter Sharing\n",
    "* Rinse and repeat for 8.3.4 which is that it did the worst\n",
    "* Each approach did a good job with some topics but not with others.\n",
    "* How can we get just the best from each method?\n",
    "    * Would make sense to create an ensemmble classifier that would consist of 3 types of one-verus-all parameter sharing!\n",
    "\n",
    "## 8.5 Part-of-Speech and Named Entity Recognition Data\n",
    "* Comes from the Computational Natural Language Learning (CoNLL) conference\n",
    "* Joint speech tagging / named entity tagging for Dutch and Spanish\n",
    "* High range within the data\n",
    "    * Melbourne: One-word entity\n",
    "    * United States of America: Phrasal entity\n",
    "\n",
    "### 8.5.1 Data Handling\n",
    "```\n",
    "DATA -> Windowing -> Split windowed data into pos tagging and named entity -> \n",
    "Task 1 Docs | Task 1 Labels -> Vectorized docs\n",
    "                            -> Labels converted to int -> Vectorized labels\n",
    "Task 2 Docs | Task 2 Labels -> Vectorized docs\n",
    "                            -> Labels converted to int -> Vectorized labels\n",
    "```\n",
    "* Baseline Single Task CoNLL Data Performance:\n",
    "    * POS: 91.7%\n",
    "    * NER: 93.2%\n",
    "\n",
    "### 8.5.2 Hard Parameter Sharing\n",
    "* Rinse + repeat of 8.2.2\n",
    "* Performance:\n",
    "    * POS: 91.8 %\n",
    "    * NER: 94.2 %\n",
    "    * NER benefits more but both tasks benefit\n",
    "\n",
    "### 8.5.3 Soft Parameter Sharing\n",
    "* Rinse + repeat of 8.2.3\n",
    "* Performance:\n",
    "    * POS: 91.7 %\n",
    "    * NER: 94.8 %\n",
    "    * Similar to baseline for POS but benefits NER\n",
    "\n",
    "### 8.5.4 Mixed Parameter Sharing\n",
    "* Rinse + repeat of 8.2.4\n",
    "* Performance:\n",
    "    * POS: 91.7 %\n",
    "    * NER: 94.6 %\n",
    "    * Similar to baseline for POS but benefits NER\n",
    "\n",
    "## 8.6 Summary\n",
    "* You can implement and apply deep learning multitask learning with hard parameter sharing (sharing layers across sub-classifiers, soft parameter sharing, and mixed parameter sharing (a combination of hard and soft parameter sharing)).\n",
    "* Multitask learning can produce significantly better results for one or all of the subtasks learned.\n",
    "* Soft parameter sharing yields the best results overall, but differences with hard parameter sharing are usually small.\n",
    "* Mixed parameter sharing does not stand out compared to the other two approaches.\n",
    "* It is up to the NLP engineer to come up with optimal combinations of layers, task combinations, and custom loss functions, using practical experimentation guided by trial and error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fafb746076eaa6f4a9c35dd52bd375d0d02af7c1d2f963d3faba917059a1fee8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
