{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Episodic memory for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Strongly supervised memory networks easily produce above-baseline results\n",
    "* Semi-supervised memory networks can produce better accuracies though!\n",
    "\n",
    "## 6.1 Memory Networks for Sequential NLP\n",
    "* Procedural memory consists of a semantic and an episodic component\n",
    "    * Semantic: More generic/abstract conceptual info\n",
    "    * Episodic: Specific memories + personal experiences\n",
    "* Most of NLP is about picking out contextual info to make a step towards interpretation\n",
    "* Ambiguities in a sentence/phrase can make it difficult to determine the contribution that a noun/verb can become\n",
    "* Question: Which part of speech should a noun/verb ambiguity get in this context?\n",
    "    * We must make sure that insertion order is preserved here!\n",
    "    * How can we transform random NLP data such that a memory network can be ingested?\n",
    "\n",
    "## 6.2 Data and Data Processing\n",
    "* Data:\n",
    "    * Data for preprositional phrase - attachment\n",
    "    * Dutch diminuitive formation data\n",
    "    * Spanish part-of-speech tagging data\n",
    "* Let's use a single retrievel pass over the stored facts\n",
    "* Also going to provide explicitly the relevant facts for answering a question\n",
    "### 6.2.1: PP Attachment Data:\n",
    "* Prepositional phrases restrict the meaning of other words in the sentence\n",
    "* Data Format:\n",
    "    * eats,pizza,with,anchovies,N\n",
    "    * dumped,sacks,into,bin,V\n",
    "        * N vs. V is what the pp is modifying\n",
    "* Also throw in data that tags the part of speech as well\n",
    "### 6.2.2 Dutch Diminutive Data\n",
    "* Features here indicate whether a syllable is stressed or not provided that the syllable doesn't have an onset or is less than 3 syllables\n",
    "    * Onset: String of consonants before the vocalic part\n",
    "    * Coda: String of consonants after the vocalic part\n",
    "* Converting Dutch diminutive data to bAbI format\n",
    "    * Define an array for holding substitutions\n",
    "    * Print the facts/questions\n",
    "### 6.2.3 Spanish Part-of-Speech Data\n",
    "* Data Format:\n",
    "    * Abogado NC B-PER\n",
    "    * General AQ I-PER\n",
    "        * 2nd column = Part of speech label for the first column\n",
    "        * Last column = Phrasal information\n",
    "            * Starting a named entity (B-PER, B for 'beginning)\n",
    "            * Being part of a named entity (I-PER, I for 'inside')\n",
    "* Process:\n",
    "    * Define a dictionary, holding the assignment of parts of speech\n",
    "    * Store the combination of the words/part of speech\n",
    "    * Keep track of ambiguities\n",
    "    * Define an ngram size\n",
    "    * Define a focus position (word position addressed in the question)\n",
    "    * Convert the focus position w/ ngram size into a story\n",
    "    * Check for any ambiguities\n",
    "    * Print the fact\n",
    "\n",
    "## 6.3 Strongly Supervised Memory Networks: Experiments and Results\n",
    "### 6.3.1 PP-Attachment\n",
    "* Base Line Results: (Test Loss / Test Accuracy = .4298 / .8162)\n",
    "* Crank up the results by utilizing external word embeddings\n",
    "### 6.3.2 Dutch Diminutives\n",
    "* Base Line Results: (Test Loss / Test Accuracy = .18 / .9137)\n",
    "* Crank up the results by utilizing external word embeddings\n",
    "### 6.3.3 Spanish Part-of-Speech Tagging\n",
    "* Base Line Results: (Test Loss / Test Accuracy = .3104 / .9006)\n",
    "* Crank up the results by incorporating linguistically richer facts\n",
    "\n",
    "* Overall: The Memory Network yields average performance w/ ~ no processing cost\n",
    "\n",
    "## 6.4 Semi-Supervised Memory Networks\n",
    "* Previously we explicitly gave the facts for answering the question\n",
    "* Can the system go and figure out which facts are important for predicting an outcome?\n",
    "    * Only needs facts, questions, and answers\n",
    "* Memory networks estimate a layer of probabilities that express the importance of a certain fact for answering a question.\n",
    "* Can we make these probabilities better by doing multiple exposures of facts to questions?\n",
    "    * Multi-hop Approach:\n",
    "        * Process the result 3 times in a row rather than once\n",
    "    * Flow:\n",
    "        * Question is matched w/ the facts vector\n",
    "        * Result -> vector p + result from embedding C\n",
    "        * Compute the output 3 times\n",
    "        * The p probabilities become re-estimated during every hop w/ every hop implementing the same matching steps\n",
    "\n",
    "## 6.5 Semi-Supervised Memory Networks: Experiments and Results\n",
    "* More bAbI datasets!\n",
    "* Indefinite knowledge: Reasoning task that includes disjunctions (or) and with answers including maybe\n",
    "* Data:\n",
    "    * Fred is either in the school or the park.\n",
    "    * Mary went back to the office.\n",
    "    * Is Fred in the school? Maybe\n",
    "* Training w/ the 3-hop network can lead to a significantly improved accuracy vs. the 1-hop network as seen w/ the above data\n",
    "* Sometimes though the multi-hop network can lead to accuracy degradation as seen when trying to test for the Spanish part of speech data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
